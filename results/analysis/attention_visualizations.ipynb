{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9: Attention visualizations for the CoCa model\n",
    "import torch.utils.data as data_utils\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from utils.dataset import MyDataset\n",
    "from utils.tokenizer import Tokenizer\n",
    "from utils.vit import SimpleViT\n",
    "from utils.model import CoCa\n",
    "\n",
    "# Setup\n",
    "device = 'cpu'\n",
    "batch_size = 256\n",
    "max_length = 23\n",
    "DATA_DIR = '../../data/'\n",
    "\n",
    "# Make tokenizer\n",
    "tokenizer = Tokenizer().load_vocab(os.path.join(DATA_DIR, 'vocab.json'))\n",
    "\n",
    "# Make datasets\n",
    "train_dataset = MyDataset(os.path.join(DATA_DIR, 'split.csv'), 'train', tokenizer, max_length)\n",
    "val_dataset = MyDataset(os.path.join(DATA_DIR, 'split.csv'), 'val', tokenizer, max_length)\n",
    "test_dataset = MyDataset(os.path.join(DATA_DIR, 'split.csv'), 'test', tokenizer, max_length)\n",
    "\n",
    "# Make dataloaders\n",
    "train_dataloader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = data_utils.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = data_utils.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Make model\n",
    "vit = SimpleViT(\n",
    "        seq_len = 2000,\n",
    "        patch_size = 40,\n",
    "        num_classes = None,\n",
    "        dim = 1024,\n",
    "        depth = 6,\n",
    "        heads = 8,\n",
    "        mlp_dim = 1024,\n",
    "        channels = 1,\n",
    "        dim_head = 64\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "indices = [1191, 1028, 368]\n",
    "contrastive_loss_weight = 0.5\n",
    "caption_loss_weight = 1.0 \n",
    "\n",
    "RESULTS_DIR = os.path.join('../models/', f'contrastive{str(contrastive_loss_weight)}')\n",
    "\n",
    "with open(os.path.join(RESULTS_DIR, 'accs.json'), 'r') as f:\n",
    "    val_accs = json.load(f)['val']\n",
    "max_epoch = val_accs.index(max(val_accs))\n",
    "\n",
    "model = CoCa(\n",
    "    dim = 512,\n",
    "    img_encoder = vit,\n",
    "    image_dim = 1024,\n",
    "    num_tokens = len(tokenizer.vocab),\n",
    "    unimodal_depth = 6,\n",
    "    multimodal_depth = 9,\n",
    "    dim_head = 64,\n",
    "    heads = 8,\n",
    "    caption_loss_weight = caption_loss_weight,\n",
    "    contrastive_loss_weight = contrastive_loss_weight,\n",
    ").to(device)\n",
    "\n",
    "# Load max epoch model\n",
    "model.load_state_dict(torch.load(os.path.join(RESULTS_DIR, f'epoch_{max_epoch}.pt'), map_location='cpu'))\n",
    "print(f'Loaded epoch {max_epoch + 1} model with val accuracy {max(val_accs)}')\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(14, 7)) \n",
    "for i, idx in enumerate(indices):\n",
    "    spectrum, smiles = test_dataset[idx]\n",
    "    \n",
    "    # Add a batch dimension for processing\n",
    "    spectrum = spectrum.unsqueeze(0)\n",
    "    smiles = smiles.unsqueeze(0)\n",
    "    \n",
    "    # Decode the SMILES string\n",
    "    decoded_smiles = tokenizer.decode(smiles[0])\n",
    "    \n",
    "    # Obtain model outputs including attention\n",
    "    loss, accuracy, outputs, query_attn, token_attn = model(\n",
    "        tokenizer, text=smiles, images=spectrum, return_loss=True, return_attention=True, layer=8\n",
    "    )\n",
    "\n",
    "    # Compute the average attention across all heads\n",
    "    query_head = query_attn.mean(dim=1).squeeze()\n",
    "    token_head = token_attn.mean(dim=1).squeeze()\n",
    "    token_head = token_head[1:]  # Skip the first token\n",
    "\n",
    "    # Compute combined attention scores\n",
    "    head = torch.matmul(query_head, token_head)\n",
    "\n",
    "    # Adjust the attention map to the length of the SMILES string\n",
    "    smiles_length = len(decoded_smiles)\n",
    "    attention_map = np.flipud(head.cpu().detach().numpy()[:smiles_length, :])\n",
    "\n",
    "    # Plot the spectrum\n",
    "    ax_spectrum = axes[0, i]\n",
    "    spectrum_data = spectrum.squeeze()\n",
    "    ax_spectrum.plot(range(len(spectrum_data)), spectrum_data)\n",
    "    ax_spectrum.invert_yaxis() \n",
    "    ax_spectrum.invert_xaxis()  \n",
    "\n",
    "    x_ticks = np.arange(0, 2001, 500) \n",
    "    x_labels = [f\"{int(round(value * 2))}\" for value in x_ticks]\n",
    "    ax_spectrum.set_xticks(x_ticks)\n",
    "    ax_spectrum.set_xticklabels(x_labels)\n",
    "\n",
    "    # Plot the attention map\n",
    "    ax_attention = axes[1, i]\n",
    "    im = ax_attention.imshow(attention_map, cmap='hot', aspect='equal')\n",
    "    ax_attention.invert_xaxis() \n",
    "    ax_attention.set_yticks(np.arange(len(decoded_smiles)))\n",
    "    ax_attention.set_yticklabels(list(decoded_smiles)[::-1], fontsize=10, rotation=90)\n",
    "\n",
    "    # Display the SMILES as an image\n",
    "    mol = Chem.MolFromSmiles(decoded_smiles)\n",
    "    mol_image = Draw.MolToImage(mol, size=(200, 200))\n",
    "    ax_smiles = axes[2, i]\n",
    "    ax_smiles.imshow(mol_image)\n",
    "    ax_smiles.axis('off')\n",
    "\n",
    "# Create a color bar in a separate axes\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_ircoca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
